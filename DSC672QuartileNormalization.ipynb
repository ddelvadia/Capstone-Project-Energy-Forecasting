{"cells":[{"metadata":{},"cell_type":"markdown","source":"#############################################################################################################################\n#############################################################################################################################\n###   REPEAT THESE MODELS WITH QUARTILE NORMALIZED MODEL FOR IMPROVEMENT\n#############################################################################################################################\n#############################################################################################################################"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\n\n# Using Skicit-learn to split data into training and testing sets\nfrom sklearn.model_selection import train_test_split\n# Import the model we are using\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, explained_variance_score\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import cross_val_score, cross_validate, cross_val_predict\nfrom sklearn.linear_model import Ridge, RidgeCV\nfrom sklearn.linear_model import ElasticNet, ElasticNetCV\nfrom sklearn.linear_model import LassoCV\nfrom sklearn import tree\nfrom sklearn import metrics \nfrom sklearn.preprocessing import quantile_transform\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import MinMaxScaler\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load solararray complete data using pandas\nfeatures=pd.read_csv('../input/df_solararray_complete.csv')\nfeatures.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=features.drop(columns=['Unnamed: 0', 'Location'], axis=1)\n#names=list(features.columns)\nfeatures.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(features.iloc[:,11])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Histograms of Couple of variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.subplot(231)\nplt.hist(features.iloc[:,10], bins='auto')\nplt.title('Histogram of Visibility')\nplt.ylabel('No of times')\n#plt.show()\n\n#for i in range(14):\nplt.subplot(232)\nplt.hist(np.log(features.iloc[:,10]+1), bins='auto',facecolor='red')\nplt.title('Log Transformation of Visibility')\nplt.ylabel('No of times')\n#plt.show()\n\n#new=[]\n#for i in range(len(features.iloc[:,11])):\n#    new.append(math.asinh(features.iloc[i,11]))  # since we can only do asinh one number at a time we are doing the for loop and adding it to the numpy\n#asinh=np.array(new)\nplt.subplot(233)\nplt.hist(np.sqrt(features.iloc[:,11]), bins='auto',facecolor='orange')\nplt.title('Square Root Transformation of Visibility')\nplt.ylabel('No of times')\n#plt.show()\n\nmn1=MinMaxScaler()\nb=mn1.fit_transform(np.array(features.iloc[:,11]).reshape(-1,1))\nplt.subplot(234)\nplt.hist(b, bins='auto',facecolor='green',)\nplt.title('Min Max Transformation of Visibility')\nplt.ylabel('No of times')\n#plt.show()\n\nyj1=PowerTransformer()\nc=yj1.fit_transform(np.array(features.iloc[:,11]).reshape(-1,1))\nplt.subplot(235)\nplt.hist(c, bins='auto',facecolor='purple',)\nplt.title('Yeo Johnson Transformation of Visibility')\nplt.ylabel('No of times')\n#plt.show()\n\nqt=QuantileTransformer(n_quantiles=10, random_state=0)\na=qt.fit_transform(np.array(features.iloc[:,11]).reshape(-1,1))\nplt.subplot(236)\nplt.hist(a, bins='auto',facecolor='blue',)\nplt.title('Quantile Transformation of Visibility')\nplt.ylabel('No of times')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.subplot(231)\nplt.hist(features.iloc[:,11], bins='auto')\nplt.title('Histogram of Wind Speed')\nplt.ylabel('No of times')\n#plt.show()\n\n#for i in range(14):\nplt.subplot(232)\nplt.hist(np.log(features.iloc[:,11]+1), bins='auto',facecolor='red')\nplt.title('Log Transformation of Wind Speed')\nplt.ylabel('No of times')\n#plt.show()\n\n#new=[]\n#for i in range(len(features.iloc[:,11])):\n#    new.append(math.asinh(features.iloc[i,11]))  # since we can only do asinh one number at a time we are doing the for loop and adding it to the numpy\n#asinh=np.array(new)\nplt.subplot(233)\nplt.hist(np.sqrt(features.iloc[:,11]+1), bins='auto',facecolor='orange')\nplt.title('Square Root Transformation of Wind Speed')\nplt.ylabel('No of times')\n#plt.show()\n\nmn1=MinMaxScaler()\nb=mn1.fit_transform(np.array(features.iloc[:,11]).reshape(-1,1))\nplt.subplot(234)\nplt.hist(b, bins='auto',facecolor='green',)\nplt.title('Min Max Transformation of Wind Speed')\nplt.ylabel('No of times')\n#plt.show()\n\nyj1=PowerTransformer()\nc=yj1.fit_transform(np.array(features.iloc[:,11]).reshape(-1,1))\nplt.subplot(235)\nplt.hist(c, bins='auto',facecolor='purple',)\nplt.title('Yeo Johnson Transformation of Wind Speed')\nplt.ylabel('No of times')\n#plt.show()\n\nqt=QuantileTransformer(n_quantiles=10, random_state=0)\na=qt.fit_transform(np.array(features.iloc[:,11]).reshape(-1,1))\nplt.subplot(236)\nplt.hist(a, bins='auto',facecolor='blue',)\nplt.title('Quantile Transformation of Wind Speed')\nplt.ylabel('No of times')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.subplot(231)\nplt.hist(features.iloc[:,12], bins='auto')\nplt.title('Histogram of Solar Elevation')\nplt.ylabel('No of times')\n#plt.show()\n\n#for i in range(14):\nplt.subplot(232)\nplt.hist(np.nan_to_num(np.log(features.iloc[:,12])), bins='auto',facecolor='red')\nplt.title('Log Transformation of Solar Elevation')\nplt.ylabel('No of times')\n#plt.show()\n\n#new=[]\n#for i in range(len(features.iloc[:,12])):\n#    new.append(math.asinh(features.iloc[i,12]))  # since we can only do asinh one number at a time we are doing the for loop and adding it to the numpy\n#asinh=np.array(new)\nplt.subplot(233)\nplt.hist(np.sqrt(features.iloc[:,11]+1), bins='auto',facecolor='orange')\nplt.title('Square Root Transformation of Solar Elevation')\nplt.ylabel('No of times')\n#plt.show()\n\nmn1=MinMaxScaler()\nb=mn1.fit_transform(np.array(features.iloc[:,12]).reshape(-1,1))\nplt.subplot(234)\nplt.hist(b, bins='auto',facecolor='green',)\nplt.title('Min Max Transformation of Solar Elevation')\nplt.ylabel('No of times')\n#plt.show()\n\nyj1=PowerTransformer()\nc=yj1.fit_transform(np.array(features.iloc[:,12]).reshape(-1,1))\nplt.subplot(235)\nplt.hist(c, bins='auto',facecolor='purple',)\nplt.title('Yeo Johnson Transformation of Solar Elevation')\nplt.ylabel('No of times')\n#plt.show()\n\nqt=QuantileTransformer(n_quantiles=10, random_state=0)\na=qt.fit_transform(np.array(features.iloc[:,12]).reshape(-1,1))\nplt.subplot(236)\nplt.hist(a, bins='auto',facecolor='blue',)\nplt.title('Quantile Transformation of Solar Elevation')\nplt.ylabel('No of times')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# last target variable is Electricity_KW_HR\n#for i in range(14):\n#    plt.hist(features.iloc[:,i], bins='auto')\n#    plt.ylabel('No of times')\n#    plt.show()\nplt.figure(figsize=(20,10))\nplt.subplot(231)\nplt.hist(features.iloc[:,13], bins='auto')\nplt.title('Histogram of Electricity (KW/h)')\nplt.ylabel('No of times')\n#plt.show()\n\n#for i in range(14):\nplt.subplot(232)\nplt.hist(np.log(features.iloc[:,13]+1), bins='auto',facecolor='red')\nplt.title('Log Transformation of Electricity (KW/h)')\nplt.ylabel('No of times')\n#plt.show()\n\nqt=QuantileTransformer(n_quantiles=10, random_state=0)\na=qt.fit_transform(np.array(features.iloc[:,13]).reshape(-1,1))\nplt.subplot(233)\nplt.hist(a, bins='auto',facecolor='blue',)\nplt.title('Quantile Transformation of Electricity (KW/h)')\nplt.ylabel('No of times')\n#plt.show()\n\nmn1=MinMaxScaler()\nb=mn1.fit_transform(np.array(features.iloc[:,13]).reshape(-1,1))\nplt.subplot(234)\nplt.hist(b, bins='auto',facecolor='green',)\nplt.title('Min Max Transformation of Electricity (KW/h)')\nplt.ylabel('No of times')\n#plt.show()\n\nyj1=PowerTransformer()\nc=yj1.fit_transform(np.array(features.iloc[:,13]).reshape(-1,1))\nplt.subplot(235)\nplt.hist(c, bins='auto',facecolor='purple',)\nplt.title('Yeo Johnson Transformation of Electricity (KW/h)')\nplt.ylabel('No of times')\n#plt.show()\n\nnew=[]\nfor i in range(len(features.iloc[:,13])):\n    new.append(math.asinh(features.iloc[i,13]))  # since we can only do asinh one number at a time we are doing the for loop and adding it to the numpy\nasinh=np.array(new)\nplt.subplot(236)\nplt.hist(new, bins='auto',facecolor='orange')\nplt.title('Arcsinh Transformation of Electricity (KW/h)')\nplt.ylabel('No of times')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# labels are the values we want to predict\nlabels=np.array(features['Electricity_KW_HR'])\n\n# Remove the labels from the features\n# axis 1 refers to the columns\nfeatures=features.drop('Electricity_KW_HR',axis=1)\n\n# saving feature names for later use\nfeature_list=list(features.columns)\n\n#convert to numpy array\nfeatures=np.array(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize using Yeo-Johnson:\n# pt3 = PowerTransformer()\n# x_t3=pt3.fit_transform(features)\n# pt4 = PowerTransformer()\n# y_t4=pt4.fit_transform(labels.reshape(-1,1))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into training and testing sets\n#train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.20, random_state = 42)\ntrain_X, test_X, train_y, test_y = train_test_split(features, labels, test_size = 0.20, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### THIS CODE IS HERE FOR JUST DRAWING HISTOGRAM ON THE TRAIN AND TEST SPLIT DATASET #################\n#### Let's draw histogram of before and after transformation\n\n#tr=pd.DataFrame(train_X)\n#tr\n#for i in range(13):\n#    plt.hist(tr.iloc[:,i], bins='auto')\n#    plt.ylabel('No of times')\n#    plt.show()\n    \n#for i in range(13):\n#    qt=QuantileTransformer(n_quantiles=10, random_state=0)\n#    a=qt.fit_transform(np.array(tr.iloc[:,i]).reshape(-1,1))\n#    plt.hist(a, bins='auto',facecolor='red',)\n#    plt.ylabel('No of times')\n#    plt.show()\n    \n#y=pd.DataFrame(train_y)\n#plt.hist(y.iloc[:,0], bins='auto')\n#plt.ylabel('No of times')\n#plt.show()\n\n#qt=QuantileTransformer(n_quantiles=10, random_state=0)\n#a=qt.fit_transform(np.array(y.iloc[:,0]).reshape(-1,1))\n#plt.hist(a, bins='auto',facecolor='red',)\n#plt.ylabel('No of times')\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize using quantile transformation\ndef quantile():\n    qt1=QuantileTransformer(n_quantiles=10, random_state=0)\n    qt2=QuantileTransformer(n_quantiles=10, random_state=0)\n    qt3=QuantileTransformer(n_quantiles=10, random_state=0)\n    qt4=QuantileTransformer(n_quantiles=10, random_state=0)\n    qt5=QuantileTransformer(n_quantiles=10, random_state=0)\n    qt6=QuantileTransformer(n_quantiles=10, random_state=0)\n\n    train_features=qt1.fit_transform(train_X) \n    test_features=qt2.fit_transform(test_X) \n    train_labels=qt3.fit_transform(train_y.reshape(-1,1))\n    test_labels=qt4.fit_transform(test_y.reshape(-1,1))\n\n    X_t=qt5.fit_transform(features) \n    y_t=qt6.fit_transform(labels.reshape(-1,1))\n    return train_features, train_labels, test_features, test_labels, X_t, y_t, qt4\n\n# normalize using Yeo Johnson transformation\ndef yeoJohnson():   \n    pt1=PowerTransformer()\n    pt2=PowerTransformer()\n    pt3=PowerTransformer()\n    pt4=PowerTransformer()\n    pt5=PowerTransformer()\n    pt6=PowerTransformer()\n\n    train_features=pt1.fit_transform(train_X) \n    test_features=pt2.fit_transform(test_X) \n    train_labels=pt3.fit_transform(train_y.reshape(-1,1))\n    test_labels=pt4.fit_transform(test_y.reshape(-1,1))\n\n    X_t=pt5.fit_transform(features) \n    y_t=pt6.fit_transform(labels.reshape(-1,1))\n    return train_features, train_labels, test_features, test_labels, X_t, y_t, qt4\n\n\n# normalize using the minMaxScaler #\ndef minMaxscaler():\n    pt1 = MinMaxScaler()\n    pt2 = MinMaxScaler()\n    pt3=MinMaxScaler()\n    pt4=MinMaxScaler()\n    pt5=MinMaxScaler()\n    pt6=MinMaxScaler()\n    \n    train_features=pt1.fit_transform(train_X) \n    test_features=pt2.fit_transform(test_X) \n    train_labels=pt3.fit_transform(train_y.reshape(-1,1))\n    test_labels=pt4.fit_transform(test_y.reshape(-1,1))\n\n    X_t=pt5.fit_transform(features) \n    y_t=pt6.fit_transform(labels.reshape(-1,1))\n    return train_features, train_labels, test_features, test_labels, X_t, y_t, pt4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Activate one of the transformation (i.e quantile, YeoJohnso, minMax, etc)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_features, train_labels, test_features, test_labels, X_t, y_t, qt4=quantile()\n#train_features, train_labels, test_features, test_labels, X_t, y_t, pt4= yeoJohnson()\ntrain_features, train_labels, test_features, test_labels, X_t, y_t, qt4= minMaxscaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's review the shape of each features\nprint('Training Features Shape:', train_features.shape)\nprint('Training Labels Shape:', train_labels.shape)\nprint('Testing Features Shape:', test_features.shape)\nprint('Testing Labels Shape:', test_labels.shape)\n\nprint('Features Shape:', X_t.shape)\nprint('Labels Shape:', y_t.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def metric_CV():\n    # The r2_squared, rmse, mse, and explained variance based on the output of the cross validation\n    test_r2 = round(scores['test_r2'].mean(), 3)\n    test_rmse = round(math.sqrt(-scores['test_neg_mean_squared_error'].mean()), 3)\n    test_mse = round((-scores['test_neg_mean_squared_error'].mean()), 3)\n    test_exp_var_mean, test_exp_var_std = round(scores['test_explained_variance'].mean(), 3), round(scores['test_explained_variance'].std()*2, 3)\n    test_MAE=round((-scores['test_neg_mean_absolute_error'].mean()), 3)\n    \n    print('With CV Metrics:',\n                  '\\nTest R-squared:\\t\\t\\t', test_r2,\n                  '\\nTest RMSE:\\t\\t\\t', test_rmse,\n                  '\\nTest MSE:\\t\\t\\t', test_mse,\n                  '\\nTest Explained Variance:\\t {0} (+/- {1})'.format(test_exp_var_mean, test_exp_var_std),\n                  '\\nTest MAE:\\t\\t\\t', test_MAE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start Different Regressions"},{"metadata":{"trusted":true},"cell_type":"code","source":"################ Linear Regression ######################\n# Create linear regression object\nlm = linear_model.LinearRegression()\n\n# Train the model using the training sets\nlm.fit(train_features, train_labels)\n\n# Make predictions using the testing set\npredictions = lm.predict(test_features)\npred_trn=lm.predict(train_features)\n\n\ntest_r2 = round(r2_score(test_labels, predictions), 3)\ntrain_r2 = round(lm.score(train_features, train_labels), 3)\nrmse = round(np.sqrt(mean_squared_error(test_labels, predictions)),5)\nrmse_trn = round(np.sqrt(mean_squared_error(train_labels, pred_trn)),5)\nmse = round(mean_squared_error(test_labels, predictions), 5)\nmse_trn = round(mean_squared_error(train_labels, pred_trn), 5)\nexp_var = round(explained_variance_score(test_labels, predictions), 3)\nexp_var_trn = round(explained_variance_score(train_labels, pred_trn), 3)\nmae= round(mean_absolute_error(predictions,test_labels), 5)\nmae_trn=round(mean_absolute_error(pred_trn,train_labels), 5)\n\nexplained_variance_score(train_labels, pred_trn)\nprint('\\nLinear Regression Model Metrics:',\n                  '\\n\\nTest R-squared:\\t\\t', test_r2,\n                  '\\nTrain R-squared:\\t', train_r2,\n                  '\\nRMSE:\\t\\t\\t', rmse,\n                  '\\nTrain RMSE:\\t\\t', rmse_trn,\n                  '\\nMSE:\\t\\t\\t', mse,\n                  '\\nTrain MSE:\\t\\t', mse_trn,\n                  '\\nExplained Variance:\\t', exp_var,\n                  '\\nTrain Explained Variance:', exp_var_trn,\n                  '\\nMAE:\\t\\t\\t', mae,\n                  '\\nTrain MAE:\\t\\t', mae_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################ Linear Regression with Cross Validation ######################\n# Create linear regression object\nscores = cross_validate(lm, X_t, y_t, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\n#scores.keys()\n#predictions = cross_val_predict(lm, features, test_labels, cv=10)\n\nprint('Linear Regression:')\nmetric_CV()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################### Lasso Regression Model ########################################\nlasso = linear_model.Lasso(alpha=1, max_iter=100)\nlasso.fit(train_features, train_labels)\n \n# Make predictions using the testing set\npredictions = lasso.predict(test_features)\npred_trn=lasso.predict(train_features)\n\ntest_r2 = round(r2_score(test_labels, predictions), 3)\ntrain_r2 = round(lasso.score(train_features, train_labels), 3)\nrmse = round(np.sqrt(mean_squared_error(test_labels, predictions)),5)\nrmse_trn = round(np.sqrt(mean_squared_error(train_labels, pred_trn)),5)\nmse = round(mean_squared_error(test_labels, predictions), 5)\nmse_trn = round(mean_squared_error(train_labels, pred_trn), 5)\nexp_var = round(explained_variance_score(test_labels, predictions), 3)\nexp_var_trn = round(explained_variance_score(train_labels, pred_trn), 3)\nmae= round(mean_absolute_error(predictions,test_labels), 5)\nmae_trn=round(mean_absolute_error(pred_trn,train_labels), 5)\n\n\n\nexplained_variance_score(train_labels, pred_trn)\nprint('Lasso Regression Model Metrics:',\n                  '\\n\\nTest R-squared:\\t\\t', test_r2,\n                  '\\nTrain R-squared:\\t', train_r2,\n                  '\\nRMSE:\\t\\t\\t', rmse,\n                  '\\nTrain RMSE:\\t\\t', rmse_trn,\n                  '\\nMSE:\\t\\t\\t', mse,\n                  '\\nTrain MSE:\\t\\t', mse_trn,\n                  '\\nExplained Variance:\\t', exp_var,\n                  '\\nTrain Explained Variance:', exp_var_trn,\n                  '\\nMAE:\\t\\t\\t', mae,\n                  '\\nTrain MAE:\\t\\t', mae_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################### Lasso Regression Model with Cross Validation ########################################\nlasso = linear_model.Lasso()\n#lasso_CV.score(train_features, train_labels) \nscores = cross_validate(lasso, X_t, y_t, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\n#print(scores.mean()) \nscores.keys()\n\nprint('Lasso Regression:')\nmetric_CV()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################### Ridge Regression ##################################\nrdg = Ridge(alpha=1.0)\nrdg.fit(train_features, train_labels) \n\n# Make predictions\npredictions=rdg.predict(test_features)\npred_trn=lm.predict(train_features)\n\n# calculate metrics\ntest_r2 = round(r2_score(test_labels, predictions), 3)\ntrain_r2 = round(rdg.score(train_features, train_labels), 3)\nrmse = round(np.sqrt(mean_squared_error(test_labels, predictions)),3)\nrmse_trn = round(np.sqrt(mean_squared_error(train_labels, pred_trn)),3)\nmse = round(mean_squared_error(test_labels, predictions), 3)\nmse_trn = round(mean_squared_error(train_labels, pred_trn), 3)\nexp_var = round(explained_variance_score(test_labels, predictions), 3)\nexp_var_trn = round(explained_variance_score(train_labels, pred_trn), 3)\nmae= round(mean_absolute_error(predictions,test_labels), 5)\nmae_trn=round(mean_absolute_error(pred_trn,train_labels), 5)\n\n\nexplained_variance_score(train_labels, pred_trn)\nprint('Ridge Regression Model Metrics:',\n                  '\\n\\nTest R-squared:\\t\\t', test_r2,\n                  '\\nTrain R-squared:\\t', train_r2,\n                  '\\nRMSE:\\t\\t\\t', rmse,\n                  '\\nTrain RMSE:\\t\\t', rmse_trn,\n                  '\\nMSE:\\t\\t\\t', mse,\n                  '\\nTrain MSE:\\t\\t', mse_trn,\n                  '\\nExplained Variance:\\t', exp_var,\n                  '\\nTrain Explained Variance:', exp_var_trn,\n                  '\\nMAE:\\t\\t\\t', mae,\n                  '\\nTrain MAE:\\t\\t', mae_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################## Ridge Regression with Cross Validation ####################\n#rdg_CV = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(features_norm, labels_norm)\n#rdg_CV.score(features, labels) \n#rdg_CV = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1], cv=10).fit(features, labels)\n\n# cross validation score evaluation. specifically the test values of each of the 10 cross fold\n#scores = cross_validate(rdg_CV, features_norm, labels_norm, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\n#print(scores.mean())\nscores = cross_validate(rdg, X_t, y_t, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\n#scores.keys()\n\nprint('Ridge Regression:')\nmetric_CV()\n#metrics.SCORERS()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################## ElasticNet Model #######################\nEN = ElasticNet(random_state=0)\nEN.fit(train_features, train_labels)\npredictions=EN.predict(test_features)\n\n# Make predictions\npredictions=EN.predict(test_features)\npred_trn=EN.predict(train_features)\n\n# calculate metrics\ntest_r2 = round(r2_score(test_labels, predictions), 3)\ntrain_r2 = round(EN.score(train_features, train_labels), 3)\nrmse = round(np.sqrt(mean_squared_error(test_labels, predictions)),3)\nrmse_trn = round(np.sqrt(mean_squared_error(train_labels, pred_trn)),3)\nmse = round(mean_squared_error(test_labels, predictions), 3)\nmse_trn = round(mean_squared_error(train_labels, pred_trn), 3)\nexp_var = round(explained_variance_score(test_labels, predictions), 3)\nexp_var_trn = round(explained_variance_score(train_labels, pred_trn), 3)\nmae= round(mean_absolute_error(predictions,test_labels), 5)\nmae_trn=round(mean_absolute_error(pred_trn,train_labels), 5)\n\n#explained_variance_score(train_labels, pred_trn)\nprint('\\nLinear Regression Model Metrics:',\n                  '\\n\\nTest R-squared:\\t\\t', test_r2,\n                  '\\nTrain R-squared:\\t', train_r2,\n                  '\\nRMSE:\\t\\t\\t', rmse,\n                  '\\nTrain RMSE:\\t\\t', rmse_trn,\n                  '\\nMSE:\\t\\t\\t', mse,\n                  '\\nTrain MSE:\\t\\t', mse_trn,\n                  '\\nExplained Variance:\\t', exp_var,\n                  '\\nTrain Explained Variance:', exp_var_trn,\n                  '\\nMAE:\\t\\t\\t', mae,\n                  '\\nTrain MAE:\\t\\t', mae_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################## ElasticNet Regression Model with Cross Validation #######################\n#EN_CV = ElasticNetCV(cv=10, random_state=0).fit(features_norm, labels_norm)\nEN_CV = ElasticNetCV(cv=10, random_state=0).fit(features, labels)\n\n# cross validation score evaluation. specifically the test values of each of the 10 cross fold\n#scores = cross_validate(EN_CV, features_norm, labels_norm, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\n#print(scores.mean()) \nscores = cross_validate(EN, X_t, y_t, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores.keys()\n\nprint('Elastic Net Regression:')\nmetric_CV()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############### Decision Tree model ######################\ndtr = tree.DecisionTreeRegressor()\ndtr.fit(train_features, train_labels)\n\n# Make predictions\npredictions=dtr.predict(test_features)\npred_trn=dtr.predict(train_features)\n\n# calculate metrics\ntest_r2 = round(r2_score(test_labels, predictions), 3)\ntrain_r2 = round(dtr.score(train_features, train_labels), 3)\nrmse = round(np.sqrt(mean_squared_error(test_labels, predictions)),3)\nrmse_trn = round(np.sqrt(mean_squared_error(train_labels, pred_trn)),3)\nmse = round(mean_squared_error(test_labels, predictions), 3)\nmse_trn = round(mean_squared_error(train_labels, pred_trn), 3)\nexp_var = round(explained_variance_score(test_labels, predictions), 3)\nexp_var_trn = round(explained_variance_score(train_labels, pred_trn), 3)\nmae= round(mean_absolute_error(predictions,test_labels), 5)\nmae_trn=round(mean_absolute_error(pred_trn,train_labels), 5)\n\n#explained_variance_score(train_labels, pred_trn)\nprint('\\nDecision Tree Regression Model Metrics:',\n                  '\\n\\nTest R-squared:\\t\\t', test_r2,\n                  '\\nTrain R-squared:\\t', train_r2,\n                  '\\nRMSE:\\t\\t\\t', rmse,\n                  '\\nTrain RMSE:\\t\\t', rmse_trn,\n                  '\\nMSE:\\t\\t\\t', mse,\n                  '\\nTrain MSE:\\t\\t', mse_trn,\n                  '\\nExplained Variance:\\t', exp_var,\n                  '\\nTrain Explained Variance:', exp_var_trn,\n                  '\\nMAE:\\t\\t\\t', mae,\n                  '\\nTrain MAE:\\t\\t', mae_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################## Decision Tree Model with Cross Validation #######################\ndtr = tree.DecisionTreeRegressor()\n#dtr.fit(features_norm, labels_norm)\ndtr.fit(features, labels)\n\n# cross validation score evaluation. specifically the test values of each of the 10 cross fold\n#scores = cross_validate(dtr, features_norm, labels_norm, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores = cross_validate(dtr, X_t, y_t, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\n\n#print(scores.mean()) \nscores.keys()\n\nprint('Decision Tree Model:')\nmetric_CV()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############# Random Forest Model #################\n# Instantiate model with 100 decision trees\nrfr = RandomForestRegressor(n_estimators = 100, random_state = 42)\n# Train the model on training data\nrfr.fit(train_features, train_labels)\n\n# Use the forest's predict method on the test data\npredictions = rfr.predict(test_features)\npred_trn=rfr.predict(train_features)\n\n\ntest_r2 = round(r2_score(test_labels, predictions), 3)\ntrain_r2 = round(rfr.score(train_features, train_labels), 3)\nrmse = round(np.sqrt(mean_squared_error(test_labels, predictions)),5)\nrmse_trn = round(np.sqrt(mean_squared_error(train_labels, pred_trn)),5)\nmse = round(mean_squared_error(test_labels, predictions), 5)\nmse_trn = round(mean_squared_error(train_labels, pred_trn), 5)\nexp_var = round(explained_variance_score(test_labels, predictions), 3)\nexp_var_trn = round(explained_variance_score(train_labels, pred_trn), 3)\nmae= round(mean_absolute_error(predictions,test_labels), 5)\nmae_trn=round(mean_absolute_error(pred_trn,train_labels), 5)\n\nexplained_variance_score(train_labels, pred_trn)\nprint('Random Forest Regression Model Metrics:',\n                  '\\n\\nTest R-squared:\\t\\t', test_r2,\n                  '\\nTrain R-squared:\\t', train_r2,\n                  '\\nRMSE:\\t\\t\\t', rmse,\n                  '\\nTrain RMSE:\\t\\t', rmse_trn,\n                  '\\nMSE:\\t\\t\\t', mse,\n                  '\\nTrain MSE:\\t\\t', mse_trn,\n                  '\\nExplained Variance:\\t', exp_var,\n                  '\\nTrain Explained Variance:', exp_var_trn,\n                  '\\nMAE:\\t\\t\\t', mae,\n                  '\\nTrain MAE:\\t\\t', mae_trn)\n\n\nfrom pprint import pprint\n# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\npprint(rfr.get_params())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#names=list(features.columns)\n#names\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfr.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features=pd.read_csv('../input/df_solararray_complete.csv')\nimportances = rfr.feature_importances_\nindices = np.argsort(importances)[::-1]\nnames = [features.feature_names[i] for i in indices]\n# Create plot\nplt.figure()\n\n# Create plot title\nplt.title(\"Feature Importance\")\n\n# Add bars\nplt.bar(range(X.shape[1]), importances[indices])\n\n# Add feature names as x-axis labels\nplt.xticks(range(X.shape[1]), names, rotation=90)\n\n# Show plot\nplt.show()\n\n#print(\"Features sorted by their score:\")\n#print(sorted(zip(map(lambda x: round(x, 4), rfr.feature_importances_), names), reverse=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tnsf_pred=qt4.inverse_transform(predictions.reshape(-1,1))\ntnsf_test_labels=qt4.inverse_transform(test_labels.reshape(-1,1))\np4=sns.regplot(x=tnsf_test_labels, y=tnsf_pred, line_kws={\"color\":\"r\",\"alpha\":0.7,\"lw\":5})\np4.set(xlabel='Test Labels', ylabel='Predicted Labels', title='Random Forest Transformed: Test Vs Predicted Labels')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.reshape(-1,1).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot of the test labels vs predictions (from cross_val_predict)\n# scatter plot of the test labels vs predictions (without cross_val_predict)\n\n# plot\n#pt4.inverse_transform(predictions.reshape(-1,1))\n#tnsf_test_labels=inverse_transform(test_labels.reshape(-1,1))\ntnsf_pred=qt4.inverse_transform(predictions.reshape(-1,1))\ntnsf_test_labels=qt4.inverse_transform(test_labels.reshape(-1,1))\nsns.regplot(x=tnsf_test_labels, y=tnsf_pred, line_kws={\"color\":\"r\",\"alpha\":0.7,\"lw\":5})\nplt.scatter(tnsf_test_labels, tnsf_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tnsf_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = [30,15]\nax=plt.plot(tnsf_test_labels, alpha=0.7, color='orange')\nax=plt.plot(tnsf_pred, alpha=0.7, color='green')\nplt.xlabel('index')\nplt.ylabel('Electricity_KW_HR')\nplt.title('Actual vs. Predicted Electricity_KW_HR')\n\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\ngreen_patch = mpatches.Patch(color='orange', label='Actual Electricity_KW_HR')\norange_patch = mpatches.Patch(color='g', label='Predicted Electricity_KW_HR by RF')\nplt.legend(handles=[green_patch, orange_patch], loc='center left', bbox_to_anchor=(1, 0.5))\n#plt.figure(figsize=(10,12))\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets plot the output of actual vs predicted for first 100 values instead of all as shown above.\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = [30,15]\n\nax=plt.plot(tnsf_test_labels[:50,0], alpha=1, color='orange')\nax=plt.plot(tnsf_pred[:50,0], alpha=1, color='g')\nplt.xlabel('index')\nplt.ylabel('Electricity_KW_HR')\nplt.title('Actual vs. Predicted Electricity_KW_HR')\n\ngreen_patch = mpatches.Patch(color='orange', label='Actual Electricity_KW_HR')\norange_patch = mpatches.Patch(color='g', label='Predicted Electricity_KW_HR by RF')\n#plt.legend(handles=[green_patch, orange_patch], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.legend(handles=[green_patch, orange_patch], loc='center left', bbox_to_anchor=(1, 0.5))\n#plt.figure(figsize=(10,12))\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tnsf_test_labels[0:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tnsf_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################## RANDOM FOREST WITH CROSS_VALIDATION #########################################\nrfr.cv = RandomForestRegressor(n_estimators=100, random_state = 42)\n#scores = cross_val_score(RFR, train_features, train_labels, cv = 10, scoring='r2')\n#scores = cross_validate(rfr.cv, features, labels, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores = cross_validate(rfr.cv, X_t, y_t, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores.keys()\n#print(scores.mean()) \n#predictions = cross_val_predict(rfr.cv, test_features, test_labels, cv=10)\n\nprint('Random Forest Model:')\nmetric_CV()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###########################  RESULT IS PASSED TO THE NEXT LINE (NO NEED TO DO THIS AGAIN; TAKES LONG TIME TO DO THIS RANDOM SEARCH AS WELL)  #######################\n################# Random Forest with Randomized grid search ####################\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\nscoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance']\n\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\n\npprint(random_grid)\n\n\n########## (TAKES A LONG TIME SINCE ITS A GRID SEARCH) Use the random grid to search for best hyperparameters ############\n# First create the base model to tune\nrfr = RandomForestRegressor(random_state = 42)\n# Random search of parameters, using 3 fold cross validation, \n# search across 100 different combinations, and use all available cores\nrfr_random = RandomizedSearchCV(estimator=rfr, param_distributions=random_grid,\n                              n_iter = 50, scoring='neg_mean_absolute_error', \n                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n                              return_train_score=True)\n\n# Fit the random search model\nrfr_random.fit(train_features, train_labels)\n\n# We can view the best parameters from fitting the random search:\nrfr_random.best_params_\n\n# fine tune it around the best numbers\nbest_random = rfr_random.best_estimator_\nbest_random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################ DECIDED TO NOT DO THE RANDOMIZED GRID SEARCH PER THE ARTICLE Random Search for Hyper-Parameter Optimization BY James Bergstra ###################\n################ http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf  ##############################\n# based on the best predictor find the predict the output\nrfr.cv = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=100,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=None,\n           oob_score=False, random_state=42, verbose=0, warm_start=False)\n#scores = cross_val_score(RFR, train_features, train_labels, cv = 10, scoring='r2')\n#scores = cross_validate(rfr.cv, features, labels, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores = cross_validate(rfr.cv, X_t, y_t, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores.keys()\n#print(scores.mean()) \n#predictions = cross_val_predict(rfr.cv, test_features, test_labels, cv=10)\n\nprint('Random Forest Model:')\nmetric_CV()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### NOW let's only work with best predictor of the Random Forest\n# let's remove the 'year' since it's only\n# Features sorted by their score:\n## [(0.9279, 'Solar_Elevation'), (0.0238, 'Hour'), (0.0118, 'Cloud_Cover_Fraction'), (0.0099, 'Month'), (0.006, 'Humidity_Fraction'), \n## (0.0058, 'Day'), (0.0046, 'Temperature'), (0.0027, 'Pressure'), (0.0024, 'Dew_Point'), (0.0021, 'Wind_Speed'), (0.0016, 'Year'), (0.0008, 'Precipitation'), (0.0007, 'Visibility')]\n\n#############################################################\n########## let's remove 'year' feature and re-run random forest again #############\n# load solararray complete data using pandas\ndf=pd.read_csv('../input/df_solararray_complete.csv')\ndf.head(3)\n\ndf=df.drop(['Unnamed: 0', 'Location', 'Year'], axis=1)\nnames=list(df.columns)\ndf.head(3)\n\n#df = pd.DataFrame(continuous_features, columns=names)\n#df.head(10)\n\n\n# labels are the values we want to predict\nlabels=np.array(df['Electricity_KW_HR'])\n\n# Remove the labels from the features\n# axis 1 refers to the columns\nfeatures=df.drop('Electricity_KW_HR',axis=1)\n\n# saving feature names for later use\nfeatures_list=list(df.columns)\n\n#convert to numpy array\nfeatures=np.array(features)\n\n# normalize using Yeo-Johnson:\npt3 = PowerTransformer()\nx_t3=pt3.fit_transform(features)\npt4 = PowerTransformer()\ny_t4=pt4.fit_transform(labels.reshape(-1,1))\n\n# Split the data into training and testing sets\ntrain_features, test_features, train_labels, test_labels = train_test_split(x_t3, y_t4, test_size = 0.20, random_state = 42)\n\n# let's review the shape of each features\nprint('Training Features Shape:', train_features.shape)\nprint('Training Labels Shape:', train_labels.shape)\nprint('Testing Features Shape:', test_features.shape)\nprint('Testing Labels Shape:', test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############# Random Forest Model #################\n# Instantiate model with 100 decision trees\nrfr = RandomForestRegressor(n_estimators = 100, random_state = 42)\n# Train the model on training data\nrfr.fit(train_features, train_labels)\n\n# Use the forest's predict method on the test data\npredictions = rfr.predict(test_features)\npred_trn=rfr.predict(train_features)\n\n\ntest_r2 = round(r2_score(test_labels, predictions), 3)\ntrain_r2 = round(rfr.score(train_features, train_labels), 3)\nrmse = round(np.sqrt(mean_squared_error(test_labels, predictions)),5)\nrmse_trn = round(np.sqrt(mean_squared_error(train_labels, pred_trn)),5)\nmse = round(mean_squared_error(test_labels, predictions), 5)\nmse_trn = round(mean_squared_error(train_labels, pred_trn), 5)\nexp_var = round(explained_variance_score(test_labels, predictions), 3)\nexp_var_trn = round(explained_variance_score(train_labels, pred_trn), 3)\nmae= round(mean_absolute_error(predictions,test_labels), 5)\nmae_trn=round(mean_absolute_error(pred_trn,train_labels), 5)\n\nexplained_variance_score(train_labels, pred_trn)\nprint('Random Forest Regression Model Metrics:',\n                  '\\n\\nTest R-squared:\\t\\t', test_r2,\n                  '\\nTrain R-squared:\\t', train_r2,\n                  '\\nRMSE:\\t\\t\\t', rmse,\n                  '\\nTrain RMSE:\\t\\t', rmse_trn,\n                  '\\nMSE:\\t\\t\\t', mse,\n                  '\\nTrain MSE:\\t\\t', mse_trn,\n                  '\\nExplained Variance:\\t', exp_var,\n                  '\\nTrain Explained Variance:', exp_var_trn,\n                  '\\nMAE:\\t\\t\\t', mae,\n                  '\\nTrain MAE:\\t\\t', mae_trn)\n\n\nfrom pprint import pprint\n# Look at parameters used by our current forest\nprint('Parameters currently in use:\\n')\npprint(rfr.get_params())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Features sorted by their score:\")\nprint(sorted(zip(map(lambda x: round(x, 4), rfr.feature_importances_), names), reverse=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=plt.plot(pd.DataFrame(pt4.inverse_transform(test_labels.reshape(-1,1))), alpha=0.7, color='orange')\nax=plt.plot(pt4.inverse_transform(predictions.reshape(-1,1)), alpha=0.7, color='green')\n\n#ax=plt.plot(tnsf_test_labels, alpha=0.7, color='orange')\n#ax=plt.plot(tnsf_pred, alpha=0.7, color='green')\n\nplt.xlabel('index')\nplt.ylabel('Electricity_KW_HR')\nplt.title('Actual vs. Predicted Electricity_KW_HR')\n\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = [30,15]\ngreen_patch = mpatches.Patch(color='Orange', label='Actual Electricity_KW_HR')\norange_patch = mpatches.Patch(color='Green', label='Predicted Electricity_KW_HR by RF')\n#plt.legend(handles=[green_patch, orange_patch], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.legend(handles=[green_patch, orange_patch], loc='center left', bbox_to_anchor=(1, 0.5))\n#plt.figure(figsize=(10,12))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets plot the output of actual vs predicted for first 100 values instead of all as shown above.\n\nax=plt.plot(pt4.inverse_transform(test_labels.reshape(-1,1))[0:50,0], alpha=0.7, color='Orange')\nax=plt.plot(pt4.inverse_transform(predictions.reshape(-1,1))[0:50,0], alpha=0.7, color='green')\nplt.xlabel('index')\nplt.ylabel('Electricity_KW_HR')\nplt.title('Actual vs. Predicted Electricity_KW_HR')\n\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = [30,15]\ngreen_patch = mpatches.Patch(color='Orange', label='Actual Electricity_KW_HR')\norange_patch = mpatches.Patch(color='Green', label='Predicted Electricity_KW_HR by RF')\n#plt.legend(handles=[green_patch, orange_patch], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.legend(handles=[green_patch, orange_patch], loc='center left', bbox_to_anchor=(1, 0.5))\n#plt.figure(figsize=(10,12))\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################## RANDOM FOREST WITH CROSS_VALIDATION #########################################\nrfr.cv = RandomForestRegressor(n_estimators=100, random_state = 42)\n#scores = cross_val_score(RFR, train_features, train_labels, cv = 10, scoring='r2')\n#scores = cross_validate(rfr.cv, features, labels, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores = cross_validate(rfr.cv, x_t3, y_t4, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores.keys()\n#print(scores.mean()) \n#predictions = cross_val_predict(rfr.cv, test_features, test_labels, cv=10)\n\nprint('Random Forest Model:')\nmetric_CV()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best find the predict the output\nrfr.cv = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=100,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=None,\n           oob_score=False, random_state=42, verbose=0, warm_start=False)\n#scores = cross_val_score(RFR, train_features, train_labels, cv = 10, scoring='r2')\n#scores = cross_validate(rfr.cv, features, labels, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores = cross_validate(rfr.cv, x_t3, y_t4, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores.keys()\n#print(scores.mean()) \n#predictions = cross_val_predict(rfr.cv, test_features, test_labels, cv=10)\n\nprint('Random Forest Model:')\nmetric_CV()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#############################  Support Vector Machine ##################################\nfrom sklearn.svm import SVR\nn_samples, n_features = 10, 5\n#rng = np.random.RandomState(0)\nclf = SVR(gamma='scale', C=1.0, epsilon=0.2)\n# Train the model on training data\nclf.fit(train_features, train_labels) \n\n\n\n# Use the forest's predict method on the test data\npredictions = clf.predict(test_features)\npred_trn=clf.predict(train_features)\n\n\ntest_r2 = round(r2_score(test_labels, predictions), 3)\ntrain_r2 = round(clf.score(train_features, train_labels), 3)\nrmse = round(np.sqrt(mean_squared_error(test_labels, predictions)),5)\nrmse_trn = round(np.sqrt(mean_squared_error(train_labels, pred_trn)),5)\nmse = round(mean_squared_error(test_labels, predictions), 5)\nmse_trn = round(mean_squared_error(train_labels, pred_trn), 5)\nexp_var = round(explained_variance_score(test_labels, predictions), 3)\nexp_var_trn = round(explained_variance_score(train_labels, pred_trn), 3)\nmae= round(mean_absolute_error(predictions,test_labels), 5)\nmae_trn=round(mean_absolute_error(pred_trn,train_labels), 5)\n\nexplained_variance_score(train_labels, pred_trn)\nprint('SUPPORT VECTOR MACHINE Model Metrics:',\n                  '\\n\\nTest R-squared:\\t\\t', test_r2,\n                  '\\nTrain R-squared:\\t', train_r2,\n                  '\\nRMSE:\\t\\t\\t', rmse,\n                  '\\nTrain RMSE:\\t\\t', rmse_trn,\n                  '\\nMSE:\\t\\t\\t', mse,\n                  '\\nTrain MSE:\\t\\t', mse_trn,\n                  '\\nExplained Variance:\\t', exp_var,\n                  '\\nTrain Explained Variance:', exp_var_trn,\n                  '\\nMAE:\\t\\t\\t', mae,\n                  '\\nTrain MAE:\\t\\t', mae_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################## SUPPORT VECTOR MACHINE WITH CROSS_VALIDATION #########################################\n#clf_cv = RandomForestRegressor(n_estimators=100, random_state = 42)\n#scores = cross_val_score(RFR, train_features, train_labels, cv = 10, scoring='r2')\nscores = cross_validate(clf, X_t, y_t, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores.keys()\n#print(scores.mean()) \n#predictions = cross_val_predict(rfr.cv, test_features, test_labels, cv=10)\n\nprint('Support Vector Machine Model:')\nmetric_CV()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############## Xgboost Model ######################\n#predXgbMinMax():\nxg = xgb.XGBRegressor()\nxg.fit(train_features, train_labels)\n#r2=xg.score(X_t, y_t)\n#pt3 = MinMaxScaler()\n#test_t=pt3.fit_transform(test)\n#pred_Elec_t=xg.predict(test_t)\n#pred_Elec=pt2.inverse_transform(pred_Elec_t.reshape(-1,1)) \n\n\n# Use the forest's predict method on the test data\npredictions = xg.predict(test_features)\npred_trn=xg.predict(train_features)\n\n\ntest_r2 = round(r2_score(test_labels, predictions), 3)\ntrain_r2 = round(clf.score(train_features, train_labels), 3)\nrmse = round(np.sqrt(mean_squared_error(test_labels, predictions)),5)\nrmse_trn = round(np.sqrt(mean_squared_error(train_labels, pred_trn)),5)\nmse = round(mean_squared_error(test_labels, predictions), 5)\nmse_trn = round(mean_squared_error(train_labels, pred_trn), 5)\nexp_var = round(explained_variance_score(test_labels, predictions), 3)\nexp_var_trn = round(explained_variance_score(train_labels, pred_trn), 3)\nmae= round(mean_absolute_error(predictions,test_labels), 5)\nmae_trn=round(mean_absolute_error(pred_trn,train_labels), 5)\n\n#explained_variance_score(train_labels, pred_trn)\nprint('SUPPORT VECTOR MACHINE Model Metrics:',\n                  '\\n\\nTest R-squared:\\t\\t', test_r2,\n                  '\\nTrain R-squared:\\t', train_r2,\n                  '\\nRMSE:\\t\\t\\t', rmse,\n                  '\\nTrain RMSE:\\t\\t', rmse_trn,\n                  '\\nMSE:\\t\\t\\t', mse,\n                  '\\nTrain MSE:\\t\\t', mse_trn,\n                  '\\nExplained Variance:\\t', exp_var,\n                  '\\nTrain Explained Variance:', exp_var_trn,\n                  '\\nMAE:\\t\\t\\t', mae,\n                  '\\nTrain MAE:\\t\\t', mae_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########################## Xgboost WITH CROSS_VALIDATION #########################################\nscores = cross_validate(xg, X_t, y_t, cv = 10, scoring=['r2','neg_mean_squared_error','neg_mean_absolute_error', 'explained_variance'])\nscores.keys()\nprint('Support Vector Machine Model:')\nmetric_CV()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's read the scenario file now for prediction on those six days"},{"metadata":{"trusted":true},"cell_type":"code","source":"# laod scenario data set \n\n# then find each of the 6 dates training value.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features, train_labels, test_features, test_labels, X_t, y_t, qt4=","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load data using pandas\n#features=pd.read_csv('C:/Users/Dhaval/Documents/CSC 672/Final_Project_Dhaval_Delvadia/2015contest_CSV/new_data/df_solararray_complete.csv')\nfeatures=pd.read_csv('../input/df_solararray_complete.csv')\nfeatures.head()\nfeatures=features.drop(['Unnamed: 0', 'Location', 'Year'], axis=1)\nfeatures.head(3)\n# take out the electricity_KW_HR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the scenario (test) file\nfeatures_snr=pd.read_csv('../input/scenario.csv')\nfeatures_snr.head()\nfeatures_snr=features_snr.drop(['Unnamed: 0', 'City', 'Year', 'Day_of_week', 'HolidayName', 'School_Day', 'Weekdays'], axis=1)\nfeatures_snr.head()\n\nfeatures_snr.fillna(features_snr.mean(), inplace=True)\n#features.query('Month == 3 & Day == 15').sort_values(by=['Hour']).groupby(['Month','Day','Hour'], as_index=False).agg(np.mean)\n\n#a=features_snr.query('Month == 3 & Day == 15')\n#b=features_snr.query('Month == 6 & Day == 26')\n#c=features_snr.query('Month == 7 & Day == 3')\n#d=features_snr.query('Month == 10 & Day == 13')\n#e=features_snr.query('Month == 11 & Day == 19')\n#f=features_snr.query('Month == 12 & Day == 25')\n#test_dates_df = pd.concat([a, b,c,d,e,f])\n#test_dates_df.head()\n\n#x_test=test_dates_df.iloc[:,[0,1,2,4,5,6,7,8,9,10,11,3]]\n#x_test.head()\n\n# normalize using quantile normalization\n# features=quantile_transform(features, n_quantiles=10, random_state=0, copy=True)\nqt7=QuantileTransformer(n_quantiles=10, random_state=0)\n\n\nScenario_test=qt7.fit_transform(x_test) \n###np.nan_to_num(Scenario_test)\n#rfr_cv.predict(Scenario_test)\n###pred=rfr_cv.predict(np.nan_to_num(Scenario_test))\n###pred\n#prediction=qt7.inverse_transform(pred.reshape(-1,1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_snr=features_snr.sort_values(by=['Month','Day','Hour'])\nfeatures_snr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg_val=features.groupby(['Month','Day','Hour']).agg('mean').reset_index()\nagg_actual_Electricity_KW_HR=agg_val['Electricity_KW_HR']\nagg_actual_Electricity_KW_HR.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_snr.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lm1 = linear_model.LinearRegression()\n\n# Train the model using the training sets\n#lm.fit(train_features, train_labels)\n\n# Make predictions using the testing set\npredictions = lm.predict(features_snr)\n#pred_trn=lm.predict(train_features)\n\n\ntest_r2 = round(r2_score(agg_actual_Electricity_KW_HR, predictions), 3)\n#train_r2 = round(lm.score(train_features, train_labels), 3)\nrmse = round(np.sqrt(mean_squared_error(agg_actual_Electricity_KW_HR, predictions)),5)\n#rmse_trn = round(np.sqrt(mean_squared_error(train_labels, pred_trn)),5)\nmse = round(mean_squared_error(agg_actual_Electricity_KW_HR, predictions), 5)\n#mse_trn = round(mean_squared_error(train_labels, pred_trn), 5)\nexp_var = round(explained_variance_score(agg_actual_Electricity_KW_HR, predictions), 3)\n#exp_var_trn = round(explained_variance_score(train_labels, pred_trn), 3)\nmae= round(mean_absolute_error(predictions,agg_actual_Electricity_KW_HR), 5)\n#mae_trn=round(mean_absolute_error(pred_trn,train_labels), 5)\n\n#explained_variance_score(train_labels, pred_trn)\nprint('\\nLinear Regression Model Metrics:',\n                  '\\n\\nsanerio R-squared:\\t\\t', test_r2,\n                  '\\nsanerio:\\t\\t\\t', rmse,\n                  '\\nsanerioMSE:\\t\\t\\t', mse,\n                  '\\nsanerio Explained Variance:\\t', exp_var,\n                  '\\nsanerio MAE:\\t\\t\\t', mae)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}